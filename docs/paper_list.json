{"arxiv": "https://arxiv.org/pdf/2311.12983", "comments": [{"comment": ["This work is both fascinating and necessary, yet it seems to overlook the representation of the median human in its analysis. The educational breakdown of the annotators, as presented, does not align with the general population's educational levels. For context:", "In the general U.S. population aged 25 and older in 2022, only 23% held a bachelor\u2019s degree as their highest degree, while 14% had advanced education (like a master\u2019s, professional, or doctoral degree), according to the Census Bureau.In contrast, the paper indicates a much higher educational level among annotators:Bachelor\u2019s Degree: 61%Master\u2019s Degree: 26%PhD: 17%This discrepancy raises questions about the representativeness of the research sample compared to the general population."], "id": "655f285529e57ae2ebdf8ffc", "up": "13"}, {"comment": ["In the level 3 example you say explicitly \"Use commas as thousands separators in the number of minutes.\". The provided answer is \"Ground truth: White; 5876\". Should it not be \"Ground truth: White; 5,876\"?"], "id": "655fa2e565bc71935d970042", "up": "2"}, {"comment": ["You're absolutely right:  \"Use commas as thousands separators in the number of minutes.\" comes from an older version of the dataset, we will remove it in the next version of the paper"], "id": "655fa3ddafee0e0078a91923", "up": "5"}, {"comment": ["\nThis work is both fascinating and necessary, yet it seems to overlook the representation of the median human in its analysis. The educational breakdown of the annotators, as presented, does not align with the general population's educational levels. For context:\nIn the general U.S. population aged 25 and older in 2022, only 23% held a bachelor\u2019s degree as their highest degree, while 14% had advanced education (like a master\u2019s, professional, or doctoral degree), according to the Census Bureau.In contrast, the paper indicates a much higher educational level among annotators:Bachelor\u2019s Degree: 61%Master\u2019s Degree: 26%PhD: 17%This discrepancy raises questions about the representativeness of the research sample compared to the general population.\n", "There is indeed likely a discrepancy that is impossible to solve between the distribution of the annotators and the general population. That being said the questions rather require fundamental abilities (planning, tool use, multi-modal understanding, etc.) than expert knowledge"], "id": "655fa40b4f2c90ed74288733", "up": "3"}, {"comment": ["Very cool benchmark, congrats! ", "Can you share any examples from levels 1 & 2 where GPT-4 got the right answer, but the human annotators didn't? I think this would be quite interesting to learn whether there's a type of multi-step question that LLMs are intrinsically better at than humans"], "id": "656058091bee953326c5250c", "up": 0}, {"comment": ["Most of the mistakes that were made by humans validators (and why we don't get a 100% human score) were attention mistakes (misreading/mistyping something for example) rather than a difference in actual capability - unless you count \"focus\" as a capability, in which case we could argue that machines in general are already better at it than most of us \ud83d\ude05 ", "@gregmialz would have specific examples of this."], "id": "656059fb08eeb810e50c9844", "up": "6"}, {"comment": ["GAIA is the touring test of AI! "], "id": "6560cba201de72cb639d0d62", "up": 0}, {"comment": ["\n\nThis work is both fascinating and necessary, yet it seems to overlook the representation of the median human in its analysis. The educational breakdown of the annotators, as presented, does not align with the general population's educational levels. For context:\nIn the general U.S. population aged 25 and older in 2022, only 23% held a bachelor\u2019s degree as their highest degree, while 14% had advanced education (like a master\u2019s, professional, or doctoral degree), according to the Census Bureau.In contrast, the paper indicates a much higher educational level among annotators:Bachelor\u2019s Degree: 61%Master\u2019s Degree: 26%PhD: 17%This discrepancy raises questions about the representativeness of the research sample compared to the general population.\n\nThere is indeed likely a discrepancy that is impossible to solve between the distribution of the annotators and the general population. That being said the questions rather require fundamental abilities (planning, tool use, multi-modal understanding, etc.) than expert knowledge\n", "i wouldn't say impossible, but not sure how feasible it is to so:", "\nrequire/validate specific standardized test results which must have been taken within X years (relative to the type of test) in the annotators c.v. prior to acceptance\nrank annotators vs. population being compared against\nannotator pay should reflect current job responsibilities and requirements to obtain\n"], "id": "6560d473cf4f0785336d96ce", "up": 0}, {"comment": ["I love that NASA question. It will be something else entirely when LLM's are nailing those level 3 questions. I mean you could wrestle the answer out with some clever and patient prompt engineering and chaining, but when it can do that zero shot... Basically magic. This oughta be the gold standard. "], "id": "6561410d79911cb9fa79a6a3", "up": 0}, {"comment": ["What is the plan for the inevitably of someone solving all the questions and putting them out on the open web? Just regularly create new problem sets?"], "id": "656613bed4b0cda0f43e0cca", "up": 0}, {"comment": ["This couples nicely with this benchmark suite ->  GPQA: A Graduate-Level Google-Proof Q&A Benchmark[https://arxiv.org/abs/2311.12022]"], "id": "65661982e1604b20586407ae", "up": "1"}, {"comment": [], "id": "6566c9d9e0977cf44f84d56d", "up": 0}, {"comment": ["@someone13574 yes these questions are quite easy to re-create or slightly modify in the case of memorization.But also: getting the right answer without a good \"trace of reasoning\" doesn't mean much on this dataset"], "id": "656701456443f1b315eb0487", "up": "1"}, {"comment": ["Thanks @clefourrier for letting us know! \ud83e\udd17"], "id": "6567057d32a48203e7f3d092", "up": "1"}, {"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nMathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models (2023)\nGPQA: A Graduate-Level Google-Proof Q&A Benchmark (2023)\nCORE-MM: Complex Open-Ended Reasoning Evaluation For Multi-Modal Large Language Models (2023)\nTencentLLMEval: A Hierarchical Evaluation of Real-World Capabilities for Human-Aligned LLMs (2023)\nEvaluating General-Purpose AI with Psychometrics (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c68a9441fd9214b4efb", "up": 0}, {"comment": ["Nice work ! Those questions are fun. It's sad the new ChatGPT with all tool (web, image, python) doesn't have a proper API so that it could be tested also. Here is a totally cherry-picked example (worked only once), and still a loss because the answer is not properly formatted :"], "id": "6567cf9149653cac9007963a", "up": "1"}, {"comment": ["\nWhat is the plan for the inevitably of someone solving all the questions and putting them out on the open web? Just regularly create new problem sets?\n", "You'd have to be a bit of a basterd to do that \ud83d\ude02 maybe someone would do it to poison the competition?", "It's certainly not something to overlook.", "Here are my thoughts:", "\nPublish 70% of the dataset, then have 30% behind a trusted API. Hugging face et. all. could easily implement this functionality. Essentially we would all have to agree that this central authority is trustworthy and unbiased. \n\nRegularly update the dataset. Requires humans and expensive. Who has the incentive to do this? \n\nSynthetic dataset generated on the fly. Is this even plausible and is it self defeating? \n\nClose your eyes and hope for the best\n\n", "\ud83d\ude02"], "id": "6568a5f326d6f7491903131f", "up": 0}, {"comment": ["People really don't care about data contamination. How about we resist running to chatgpt with the dataset ha."], "id": "6568ca17cc9ee97196236744", "up": 0}, {"comment": ["Hi! Thank you all for your points about data contamination!", "This is precisely why ", "\nwe only released the answers on the validation set, not on the test set, which is considerably bigger\nwe released the precise recipe for generating such a dataset, in the hope that it will be extended with time\nwe ask for the reasoning trace of the model\n", "But since, at the moment, even the best models don't reach more than a few points on level 3, I think we have some time before us :)"], "id": "6568cb9ab5325fc770dedd34", "up": "1"}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.12983", "name": "GAIA: a benchmark for General AI Assistants", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13073", "comments": [{"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nMoVideo: Motion-Aware Video Generation with Diffusion Models (2023)\nLAMP: Learn A Motion Pattern for Few-Shot-Based Video Generation (2023)\nVideoCrafter1: Open Diffusion Models for High-Quality Video Generation (2023)\nDynamiCrafter: Animating Open-domain Images with Video Diffusion Priors (2023)\nConditionVideo: Training-Free Condition-Guided Text-to-Video Generation (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c6f90aa29ce91c26555", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13073", "name": "FusionFrames: Efficient Architectural Aspects for Text-to-Video Generation Pipeline", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13384", "comments": [{"comment": ["paper"], "id": "6563cabd6ff1b91e2848cfa0", "up": 0}, {"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nDepth-Regularized Optimization for 3D Gaussian Splatting in Few-Shot Images (2023)\niNVS: Repurposing Diffusion Inpainters for Novel View Synthesis (2023)\nDatasetNeRF: Efficient 3D-aware Data Factory with Generative Radiance Fields (2023)\nControl3D: Towards Controllable Text-to-3D Generation (2023)\nConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c591e159921a0a5f796", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13384", "name": "LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13600", "comments": [{"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nLQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning (2023)\nText-to-Sticker: Style Tailoring Latent Diffusion Models for Human Expression (2023)\nStyleBART: Decorate Pretrained Model with Style Adapters for Unsupervised Stylistic Headline Generation (2023)\nSTEER: Unified Style Transfer with Expert Reinforcement (2023)\nMulti-Concept T2I-Zero: Tweaking Only The Text Embeddings and Nothing Else (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c83d4b0cda0f473ac59", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13600", "name": "ZipLoRA: Any Subject in Any Style by Effectively Merging LoRAs", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.12908", "comments": [{"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nUsing Human Feedback to Fine-tune Diffusion Models without Any Reward Model (2023)\nText-to-Sticker: Style Tailoring Latent Diffusion Models for Human Expression (2023)\nAligning Text-to-Image Diffusion Models with Reward Backpropagation (2023)\nEnhancing Diffusion Models with Text-Encoder Reinforcement Learning (2023)\nSuperHF: Supervised Iterative Learning from Human Feedback (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c52118497d0af952f19", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.12908", "name": "Diffusion Model Alignment Using Direct Preference Optimization", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13231", "comments": [{"comment": ["It looks like the author has made the code public.https://github.com/yk7333/d3po"], "id": "6560712ca4c9a1dd9444faa4", "up": 0}, {"comment": ["You had me at D3PO \ud83d\ude02"], "id": "656142cb8631d43d2b8f36da", "up": 0}, {"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nDiffusion Model Alignment Using Direct Preference Optimization (2023)\nAligning Text-to-Image Diffusion Models with Reward Backpropagation (2023)\nEnhancing Diffusion Models with Text-Encoder Reinforcement Learning (2023)\nSafe RLHF: Safe Reinforcement Learning from Human Feedback (2023)\nCOPF: Continual Learning Human Preference through Optimal Policy Fitting (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c4293e30c8a600dcab0", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13231", "name": "Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13435", "comments": [{"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nVLM-Eval: A General Evaluation on Video Large Language Models (2023)\nVamos: Versatile Action Models for Video Understanding (2023)\nVideo-LLaVA: Learning United Visual Representation by Alignment Before Projection (2023)\nVideo-Bench: A Comprehensive Benchmark and Toolkit for Evaluating Video-based Large Language Models (2023)\nMM-VID: Advancing Video Understanding with GPT-4V(ision) (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c7b295a50cb58b839f7", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13435", "name": "PG-Video-LLaVA: Pixel Grounding Large Video-Language Models", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13601", "comments": [{"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nSEGIC: Unleashing the Emergent Correspondence for In-Context Segmentation (2023)\nTowards Training-free Open-world Segmentation via Image Prompting Foundation Models (2023)\nOV-PARTS: Towards Open-Vocabulary Part Segmentation (2023)\nZEETAD: Adapting Pretrained Vision-Language Model for Zero-Shot End-to-End Temporal Action Detection (2023)\nUniPose: Detecting Any Keypoints (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c6077d8a948ac982aeb", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13601", "name": "Visual In-Context Prompting", "publish_date": null, "vote_num": null}
{"arxiv": "https://arxiv.org/pdf/2311.13141", "comments": [{"comment": ["Isn't it the same as \"circular_padding\u201d argument in \u201cStableDiffusionPanoramaPipeline\u201d https://github.com/huggingface/diffusers/pull/4025 ? "], "id": "6560bc17f231380a6cba3db6", "up": 0}, {"comment": ["This is an automated message from the Librarian Bot. I found the following papers similar to this paper. ", "The following papers were recommended by the Semantic Scholar API ", "\nCustomizing 360-Degree Panoramas through Text-to-Image Diffusion Models (2023)\nDreamSpace: Dreaming Your Room Space with Text-Driven Panoramic Texture Propagation (2023)\nZero123++: a Single Image to Consistent Multi-view Diffusion Base Model (2023)\nParagraph-to-Image Generation with Information-Enriched Diffusion Model (2023)\nText-Guided Texturing by Synchronized Multi-View Diffusion (2023)\n", " Please give a thumbs up to this comment if you found it helpful!", " If you want recommendations for any Paper on Hugging Face checkout this Space"], "id": "65670c4977d8a948ac98250b", "up": 0}], "feature_data": "2023-11-23", "huggingface_url": null, "id": "2311.13141", "name": "Diffusion360: Seamless 360 Degree Panoramic Image Generation based on Diffusion Models", "publish_date": null, "vote_num": null}
